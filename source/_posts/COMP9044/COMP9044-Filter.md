---
title: "Unix/Linux 文本处理利器：常用过滤器 (Unix Text Processing Filters)"
date: 2026-02-19 15:25:37
tags:
  - Unix
  - Linux
  - Shell
  - Text Processing
categories:
  - COMP9044
---

# Unix/Linux 文本处理利器：常用过滤器指南

在 Unix/Linux 环境下，一切皆文件。高效处理文本数据是系统管理、日志分析和日常开发的核心技能。本文总结了最高频率使用的文本“过滤器”命令，助你快速掌握管道 (Pipeline) 哲学的精髓。

---

## 一、 核心搜索与匹配 (Search & Match)

搜索是处理文本的第一步，`grep` 是其中绝对的王者。

### **1. `grep` (Global Regular Expression Print)**
*   **功能**：在输入流或文件中搜索符合特定模式 (Pattern) 的行，并将匹配行输出。
*   **核心记忆点**：它是按 **行** 处理的过滤器。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-E`** | 使用扩展正则表达式 (Extended Regex) | **E**xtended | **必记**。建议默认开启，否则 `+`, `?`, `\|` 等符号需转义。 |
| **`-i`** | 忽略大小写 | **I**gnore case | 匹配 `error` 同时也能匹配 `Error` 或 `ERROR`。 |
| **`-v`** | 反向匹配，打印**不**匹配的行 | In**V**ert | 用于过滤掉已知无关信息。 |
| **`-c`** | 只打印匹配行的**数量** | **C**ount | 仅输出统计数字，不显示行内容。 |
| **`-w`** | 强制匹配整个单词 | **W**ord | 避免 `cat` 误匹配到 `category`。 |

**使用示例：**
*   **样例文本 (`logs.txt`)**：
    ```text
    10:01 INFO User login: admin
    10:02 ERROR DB connection failed
    10:03 INFO Data saved
    ```
*   **样例命令**：`grep "ERROR" logs.txt`
*   **样例输出**：
    ```text
    10:02 ERROR DB connection failed
    ```

---

## 二、 文本切片与提取 (Slicing)

用于从庞大的文本流中提取特定的部分（按行或按列）。

### **2. `cut`**
*   **功能**：按 **列** (字段) 提取文本内容。
*   **核心记忆点**：处理表格化数据（如 CSV, `/etc/passwd`）。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-f`** | 指定提取字段 (Fields) | **F**ield | **从 1 开始计数**。如 `-f 1` (第1列)。 |
| **`-d`** | 指定列的分隔符 (Delimiter) | **D**elimiter | **默认为 Tab**。处理 CSV 需显式用 `-d ','`。 |
| **`-c`** | 按字符位置提取 | **C**haracter | 如 `-c 1-5` 提取每行前 5 个字符。 |

**使用示例：**
*   **样例文本 (`user.csv`)**：
    ```text
    id,name,email
    1,Alice,alice@example.com
    2,Bob,bob@example.com
    ```
*   **样例命令**：`cut -d ',' -f 2 user.csv`
*   **样例输出**：
    ```text
    name
    Alice
    Bob
    ```

### **3. `head` / `tail`**
*   **功能**：分别输出输入的 **前 N 行** 或 **后 N 行**。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-n`** | 指定显示的行数 | **N**umber | 如 `head -n 5`。若不指定，默认通常显示 10 行。 |
| **`-f`** | 实时追踪文件增长 (tail 特有) | **F**ollow | 常用于实时查看日志。 |

---

## 三、 字符级转换 (Transformation)

### **4. `tr` (Translate)**
*   **功能**：基于 **字符** (而非单词) 进行替换、删除或压缩。
*   **核心记忆点**：`tr` **不接受文件名作为参数**，必须通过管道 `|` 或重定向 `<` 接收输入。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-d`** | 删除匹配字符集中的字符 | **D**elete | 如 `tr -d '0-9'` 删除所有数字。 |
| **`-s`** | 将连续重复字符压缩为一个 | **S**queeze | 如 `tr -s ' '` 将多个连续空格压制为一个。 |
| **`-c`** | 对字符集取反 (Complement) | **C**omplement | 操作除指定字符集 **以外** 的字符。 |

> **💡 技术贴士：`tr` 的“固执”设计**
> *   **纯粹的过滤器**：`tr` 是 Unix 中极少数**完全不支持**文件名参数的命令。它没有 `tr 'a' 'b' file.txt` 这种用法，必须配合管道 `|` 或 `<` 使用。
> *   **字符 vs 单词**：`tr` 处理的是 **字符级** 映射。`tr 'apple' 'ABCDE'` 并不是替换单词，而是把 a 换成 A，p 换成 B... 如果你需要处理单词，请使用 `sed`。


**使用示例：**
*   **样例输入**：`echo "Hello 123 World" | tr -d '0-9'`
*   **样例输出**：
    ```text
    Hello  World
    ```

---

## 四、 统计、排序与去重 (Aggregation & Sorting)

这三个命令通常组合使用，构建小型的数据处理流水线。

### **5. `wc` (Word Count)**
*   **功能**：统计行数、单词数和字节数。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-l`** | 只统计行数 | **L**ines | 统计查询结果总数时最常用。 |
| **`-w`** | 只统计单词数 | **W**ords | 以空白符为分隔依据。 |

### **6. `sort`**
*   **功能**：对文本行进行排序。
*   **核心记忆点**：默认按 **字典序** (ASCII) 排序。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-n`** | 按 **数值** 大小排序 | **N**umeric | **从小到大**。处理数值数据时必须加此参数。 |
| **`-r`** | 逆序排列 (降序) | **R**everse | **从大到小**。通常与 `-n` 配合使用。 |
| **`-k`** | 指定排序列 | **K**ey | 如 `-k 2` 按第二列内容排序。 |
| **`-t`** | 指定列分隔符 | **T**ag / Separa**T**or | 配合 `-k` 使用。 |

### **7. `uniq` (Unique)**
*   **功能**：去除或统计 **相邻** 的重复行。
*   **核心记忆点**：**使用前必须先排序 (`sort`)**。

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-c`** | 显示每行重复出现的次数 | **C**ount | 构建“热点数据统计”常用此项。 |
| **`-d`** | 只显示重复过的行 | **D**uplicate | |
| **`-u`** | 只显示从未重复的行 | **U**nique | |

**使用示例：**
*   **样例文本 (`fruits.txt`)**：
    ```text
    apple
    orange
    apple
    banana
    orange
    apple
    ```
*   **样例命令**：`sort fruits.txt | uniq -c`
*   **样例输出**：
    ```text
    3 apple
    1 banana
    2 orange
    ```

---

## 五、 流编辑器 (Stream Editor)

### **8. `sed`**
*   **功能**：通过编程方式编辑文本流（替换、删除、提取）。
*   **核心逻辑**：读取一行 -> 执行命令 -> 输出结果。

| 选项/命令 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-n`** | 静默模式，不自动打印每一行 | **N**o printing | 通常配合 `p` 命令精确控制输出。 |
| **`s`** | 替换命令 (Substitute) | **S**ubstitute | 经典格式 `s/old/new/g`。 |
| **`p`** | 打印命令 (Print) | **P**rint | 如 `sed -n '1,5p'` (仅打印 1-5 行)。 |
| **`d`** | 删除命令 (Delete) | **D**elete | 如 `sed '/debug/d'` (删除含 debug 的行)。 |

> **💡 技术贴士：为什么 `sed` 语法这么特别？**
> *   **脚本引擎**：不同于 `grep -i` 这种开关式的**选项**，`'s/old/new/g'` 是写给 `sed` 内部引擎看的**代码**。
> *   **行级处理**：`sed` 每次处理文本中的**一行**。它比 `tr` 强大得多，可以执行多步逻辑重写、按行号操作等。


**使用示例：**
*   **样例输入**：`echo "I love Python" | sed 's/Python/Linux/'`
*   **样例输出**：
    ```text
    I love Linux
    ```

---

## 六、 文件系统与逻辑连接

### **9. `find`**
*   **功能**：在目录树中递归查找符合条件的文件。
*   **核心语法**：`find [路径] [表达式]`

| 选项 | 作用 | 记忆逻辑 (Mnemonic) | 注意事项 |
| :--- | :--- | :--- | :--- |
| **`-name`** | 按文件名查找 | **Name** | 支持通配符，如 `'*.log'`（建议加引号防止 Shell 提前展开）。 |
| **`-type`** | 按文件类型查找 | **Type** | `f` 代表文件，`d` 代表目录。 |
| **`-mtime`** | 按修改时间查找 | **M**-**Time** | `-1` 表示 24 小时内修改过的。 |

> **💡 `-type` 怎么用？**
> 你不能直接写 `find -type f "filename"`。正确的逻辑是：`find [哪里找] -type [找什么类型] -name [叫什么名字]`。
> *   **示例**：在当前目录查找名为 `test.py` 的文件：`find . -type f -name "test.py"`

### **10. `xargs`**
*   **功能**：参数构建器。将标准输入转换为命令行参数。

**使用示例：**
*   **场景 1：基础用法 (参数在末尾)**
    查找并删除：`find . -name "*.tmp" | xargs rm`
*   **场景 2：进阶用法 (使用 `-I` 指定位置)**
    如果你想把找到的文件移动到 `backup` 目录，`rm` 只接受末尾参数，但 `mv` 需要把文件放在中间：
    `find . -name "*.log" | xargs -I {} mv {} ./backup/`
    *(这里的 `{}` 是占位符，代表管道传过来的每一个文件名)*

---

## 七、 实战避坑指南 (Common Pitfalls)

在 COMP9044 的实验和考试中，以下三个“坑”最容易扣分：

### **1. `cut` 无法处理连续空格**
`cut` 非常死板。如果数据是 `1    Alice`（中间多个空格），`cut -d ' ' -f 2` 会得到一个空字符串。
*   **解决方案**：先用 `tr -s ' '` 压缩空格，或者改用强大的 `awk`。
    *   ❌ `ls -l | cut -d ' ' -f 5` (报错或结果不对)
    *   ✅ `ls -l | tr -s ' ' | cut -d ' ' -f 5`

### **2. `find` 的通配符必须加引号**
如果你执行 `find . -name *.txt`，Shell 会在 `find` 运行前就把 `*.txt` 展开成当前目录的文件名。如果当前目录有多个 txt，`find` 会报 `paths must precede expression` 错误。
*   **金律**：**永远**对 `find` 的 `-name` 参数加引号：`find . -name "*.txt"`。

### **3. `uniq` 必须紧跟在 `sort` 后面**
`uniq` 只能去除**相邻**的重复行。
*   **错误示例**：输入 `A, B, A`，直接 `uniq` 还是 `A, B, A`。
*   **正确写法**：`sort file | uniq`。

---

## 总结：管道 (Pipeline) 组合拳

这就是 Unix 的哲学：**每个工具只做好一件事，通过管道连接它们。**

**综合练习**：统计访问日志中 TOP 10 的 IP 地址
`cat access.log | cut -d ' ' -f 1 | sort | uniq -c | sort -rn | head -n 10`